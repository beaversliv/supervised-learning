{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "training_filename = 'dtrain123.dat'\n",
    "test_filename = 'dtest123.dat'\n",
    "filename = 'zipcombo.dat'\n",
    "data = np.loadtxt(filename)\n",
    "## define feature vector x and true value y\n",
    "x = data[:,1:]\n",
    "y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_result_tree(x,y,num_tree,runs):\n",
    "\n",
    "    training_set_errors = np.zeros((len(num_tree), runs))\n",
    "    test_set_errors = np.zeros((len(num_tree), runs))\n",
    "\n",
    "    for t in range(len(num_tree)):\n",
    "        tree = num_tree[t]\n",
    "        for run in range(runs):\n",
    "            print(\"Now doing run \", run+1, \"/\", runs, \" for \",\", num_tree=\",tree,\".........\", end='\\r')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "            rfc_classifier = RandomForestClassifier(n_estimators=tree,max_depth=None, random_state=0)\n",
    "            rfc_classifier.fit(X_train, y_train)\n",
    "\n",
    "            test_labels = rfc_classifier.predict(X_test)\n",
    "            test_errors = sum(y_test != test_labels) / len(y_test)\n",
    "\n",
    "            train_labels = rfc_classifier.predict(X_train)\n",
    "            train_errors = sum(y_train != train_labels) / len(y_train)\n",
    "\n",
    "            training_set_errors[t, run] = train_errors\n",
    "            test_set_errors[t, run] = test_errors\n",
    "    return training_set_errors, test_set_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_table(training_set_errors,test_set_errors):\n",
    "    train_mean=np.mean(training_set_errors,axis=1)\n",
    "    train_std=np.std(training_set_errors,axis=1)\n",
    "    test_mean=np.mean(test_set_errors,axis=1)\n",
    "    test_std=np.std(test_set_errors,axis=1)\n",
    "\n",
    "    mean_std = []\n",
    "    for i in range(len(train_mean)):\n",
    "        data_t = []\n",
    "        colomn_1 = \"{0:.4f} +- {1:.4f}\".format(train_mean[i]*100,train_std[i]*100)\n",
    "        data_t.append(colomn_1)\n",
    "        colomn_2 = \"{0:.4f} +- {1:.4f}\".format(test_mean[i]*100,test_std[i]*100)    \n",
    "        data_t.append(colomn_2)\n",
    "        mean_std.append(data_t)\n",
    "    return mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0:18:13.635669  , num_tree= 1000 .........\n"
     ]
    }
   ],
   "source": [
    "num_tree = np.array([10,100,500,1000])\n",
    "runs = 20        \n",
    "startTime = datetime.now()\n",
    "training_set_ntr_errors, test_set_ntr_errors=basic_result_tree(x,y,num_tree,runs)\n",
    "time_tree_ntr_basic = datetime.now() - startTime\n",
    "print(\"Time taken: \", time_tree_ntr_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean_std(%)</th>\n",
       "      <th>test_mean_std(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1116 +- 0.0438</td>\n",
       "      <td>6.4167 +- 0.4464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>3.6989 +- 0.3512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>3.3118 +- 0.3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>3.5806 +- 0.4617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_mean_std(%)  test_mean_std(%)\n",
       "10    0.1116 +- 0.0438  6.4167 +- 0.4464\n",
       "100   0.0000 +- 0.0000  3.6989 +- 0.3512\n",
       "500   0.0000 +- 0.0000  3.3118 +- 0.3576\n",
       "1000  0.0000 +- 0.0000  3.5806 +- 0.4617"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to construct table\n",
    "Tree_mean_std=construct_table(training_set_ntr_errors,test_set_ntr_errors)\n",
    "pd.DataFrame(data=Tree_mean_std,index=num_tree,columns=['train_mean_std(%)','test_mean_std(%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_tree(x,y,num_tree,k):\n",
    "    \"\"\"\n",
    "    This function performs a k-fold cross validation on X, using a kernel of \"kernel_choice\" with parameter d.\n",
    "    :param X: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param d: the parameter of the kernel\n",
    "    :param k: the number of splits, i.e. the k parameter in k-fold Cross Validation\n",
    "    :return: the mean of test error across the k runs of the CV process and its standard deviation\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    mistake_arr = np.zeros(k)\n",
    "    i = 0\n",
    "    \n",
    "    for train_index, cv_index in kf.split(x):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        X_train = x[train_index]\n",
    "        X_cv = x[cv_index]\n",
    "        y_train = y[train_index]\n",
    "        y_cv = y[cv_index]\n",
    "    \n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        rfc_classifier = RandomForestClassifier(n_estimators=tree,max_depth=None, random_state=0)\n",
    "        rfc_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_labels = rfc_classifier.predict(X_cv)\n",
    "        mistakes = sum(y_cv != predicted_labels)\n",
    "        mistake_arr[i] = mistakes / len(y_cv)\n",
    "        i += 1\n",
    "        \n",
    "    return mistake_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_process_tree(x,y,num_tree,runs):\n",
    "    \"\"\"\n",
    "    This function performs 5-fold cross validation, multiple times (specified by runs argument) across the different\n",
    "    values of d specified in d_arr using the kernel specified in kernel_choice\n",
    "    :param d_arr: an array of d values\n",
    "    :param runs: The number of runs to repeat the CV process\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param calculate_confusions: Whether or not to also calculate confusions on the test set\n",
    "    :return: the array of d_stars, the test_errors and the confusions found\n",
    "    \"\"\"\n",
    "    tree_stars = np.zeros(runs)\n",
    "    test_errors = np.zeros(runs)\n",
    "    \n",
    "    for run in range(runs):\n",
    "        single_confusion_mtx = np.zeros(shape = (10,10))\n",
    "        # In each run we will iterate through the d array and use all possible values of d\n",
    "        # Allocate 80/20 percent for training and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "        CV_means = np.zeros(len(num_tree))\n",
    "        for i in range(len(num_tree)):\n",
    "            print(\"Now doing run \", run+1, \"/\", runs, \" for d=\", num_tree[i], \".........\", end='\\r')\n",
    "            mistake = cross_validation_tree(X_train, y_train,num_tree[i],k=5)\n",
    "            CV_means[i] = mistake\n",
    "            \n",
    "        # Train in whole 80% now with c_star\n",
    "        tree_stars[run] = num_tree[CV_means.argmin()]\n",
    "        # Train on whole of 80%\n",
    "        rfc_classifier = RandomForestClassifier(n_estimators=tree,max_depth=None, random_state=0)\n",
    "        rfc_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_labels = rfc_classifier.predict(X_test)\n",
    "        \n",
    "        test_error = sum(y_test != predicted_labels) / len(y_test)\n",
    "        test_errors[run] = test_error\n",
    "    return tree_stars,test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  1:26:53.404987 d= 1000 .........\n",
      "Mean c*:  382.0  with std:  363.4501341312175\n",
      "Mean test error(%):  3.2580645161290325  with std(%):  0.28570602700185843\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "num_tree = np.array([10,100,500,1000])\n",
    "startTime = datetime.now()\n",
    "tree_stars_array, test_errors_array = cv_process_tree(x,y,num_tree,runs)\n",
    "time_pp_cv = datetime.now() - startTime\n",
    "print(\"Time taken: \", time_pp_cv)\n",
    "print(\"Mean c*: \", tree_stars_array.mean(), \" with std: \", np.std(tree_stars_array))\n",
    "print(\"Mean test error(%): \", test_errors_array.mean()*100, \" with std(%): \", np.std(test_errors_array)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
