{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "training_filename = 'dtrain123.dat'\n",
    "test_filename = 'dtest123.dat'\n",
    "filename = 'zipcombo.dat'\n",
    "data = np.loadtxt(filename)\n",
    "## define feature vector x and true value y\n",
    "x = data[:,1:]\n",
    "y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Kernel(x1,x2,d):\n",
    "    \"\"\"\n",
    "    Constructions the polynomial kernel matrix of order d\n",
    "    :param x1: the first set of observations\n",
    "    :param x2: the second set of observations\n",
    "    :param d: the order of polynomial\n",
    "    :return: the polynomial kernel\n",
    "    \"\"\"\n",
    "    K = (x1 @ x2.T)**d\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Kernel(A,B,c):\n",
    "    \"\"\"\n",
    "    A: a*n matrix\n",
    "    B: b*n matrix, where 'a' may equal to 'b'\n",
    "    Distance: the pairwise distances a*b matrix\n",
    "    c: the constant scale of the exponential factor\n",
    "    return: the kernel matrix K\n",
    "    \"\"\"\n",
    "    p1 = np.sum(A**2,axis=1)[:,np.newaxis]\n",
    "    p2 = np.sum(B**2,axis=1)\n",
    "    p3 = -2*np.dot(A,B.T)\n",
    "    Distances = p1+p2+p3\n",
    "    K = np.exp(-c*Distances)\n",
    "    return K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate K(xi,xt) in training since 2 kernel is considered\n",
    "def train_kernel(x,d,kernel_choice):\n",
    "    \"\"\"\n",
    "    parameter\n",
    "    -----------------------\n",
    "    x: train set, feature matrix\n",
    "    d: dimension\n",
    "    kernel_choice: polynomial or Gaussian\n",
    "    return : kernel trick used in training x\n",
    "    \"\"\"\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x,x,d)\n",
    "    else:\n",
    "        K_train = Gaussian_Kernel(x,x,c=d)\n",
    "    return K_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kernel(x1,x2,d,kernel_choice):\n",
    "    \"\"\"\n",
    "    Calculates the kernel function of matrix x1 and x2.\n",
    "    :param x1: the first matrix x1\n",
    "    :param x2: the first matrix x2\n",
    "    :param d: is either the order of the polynomial kernel or the constant in the gaussian kernel\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :return: the kernel matrix\n",
    "    \"\"\"\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_test = Polynomial_Kernel(x1,x2,d)\n",
    "    else:\n",
    "        kernel_choice=='Gaussian'\n",
    "        K_test = Gaussian_Kernel(x1,x2,c=d)\n",
    "    return K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_epoch(x, y, alpha, K_train):\n",
    "    \"\"\"\n",
    "    Given a set of weights alpha, this function goes through the whole set of examples in x, one by one\n",
    "    and iteratively update the weights if a mistake has happened.\n",
    "    :param x: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param y_arr: the transformed labels matrix\n",
    "    :param alpha: the set of weights\n",
    "    :param K_train: the kernel matrix as calculated over x\n",
    "    :return: the updated weights alpha and the number of errors made while going through the points\n",
    "    \"\"\"\n",
    "    # Number of examples\n",
    "    m = x.shape[0] \n",
    "    num_errors = 0\n",
    "\n",
    "    for t in range(m):\n",
    "        # Find our training set\n",
    "        x_t = x[t,:] #n size (1,10)\n",
    "        y_t = y[t]\n",
    "        # pred_t computes \\sum^{t-1}_{i=0} {(alpha_i K(x_t, x_i))}, \n",
    "        # which is regarded as the confidence in each class\n",
    "        confidence = alpha.T @K_train[t,:]\n",
    "        \n",
    "        for index in range(len(confidence)):\n",
    "            if (confidence[index]>0):\n",
    "                if index!= y_t:\n",
    "                    num_errors+=1\n",
    "                    alpha[t][index]+=-1\n",
    "            if (confidence[index]<=0):\n",
    "                if index == y_t:\n",
    "                    num_errors+=1\n",
    "                    alpha[t][index]+=1\n",
    "            \n",
    "            # Store alpha_t into the matrix for future reference\n",
    "    return alpha, num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One vs. rest: train k classifiers to identify k classes\n",
    "def perceptron_train(x, y, d, kernel_choice='Polynomial', convergence_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Trains a perceptron based on the one vs. rest approach, i.e. train k classifiers to identify k classes\n",
    "    :param x: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param d: is either the order of the polynomial kernel or the constant in the gaussian kernel\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param convergence_threshold: the threshold value upon we stop updating the perceptron, if the difference\n",
    "    in errors was smaller than that\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    classes_num = 10 #number of classes \n",
    "     \n",
    "    error_per_epoch = []\n",
    "    alpha = np.zeros((m,classes_num)) #Need to store alpha array at all iteration, as we need it to compute confidence\n",
    "    \n",
    "    K_train = train_kernel(x, d, kernel_choice)    \n",
    "    epochs = 0\n",
    "    while True:\n",
    "        alpha, num_errors = perceptron_epoch(x, y, alpha, K_train)\n",
    "        \n",
    "        error_rate_current = error_per_epoch[-1] / x.shape[0] if epochs > 0 else 0\n",
    "        error_rate_next = num_errors / x.shape[0]\n",
    "\n",
    "        error_per_epoch.append(num_errors)\n",
    "        if epochs > 0 and (error_rate_next > error_rate_current or \\\n",
    "            error_rate_current - error_rate_next < convergence_threshold):\n",
    "            break\n",
    "            \n",
    "        epochs += 1\n",
    "\n",
    "    return alpha, error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(x_test,x_train,y_test, alphas, d, kernel_choice='Polynomial'):\n",
    "    \"\"\"\n",
    "    This function predicts the labels for a given set of observations.\n",
    "    :param x_test: the set of observations to predict\n",
    "    :param x_train: the observations in which the perceptron has been trained on\n",
    "    :param y_test: the true labels of x_test\n",
    "    :param alphas: the set of weights of the perceptron\n",
    "    :param d: is either the order of the polynomial kernel or the constant in the gaussian kernel\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :return: the number of mistakes that the perceptron made, the predictions as well as the confidence values.\n",
    "    \"\"\"\n",
    "    # Calculate the Kernel matrix\n",
    "    K_test = test_kernel(x_train, x_test, d, kernel_choice)\n",
    "    \n",
    "    # Compute the confidence\n",
    "    confidence = (alphas.T @ K_test).T\n",
    "    \n",
    "    # Compute mistakes and predictions\n",
    "    preds = np.zeros(confidence.shape)\n",
    "    mistakes = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        y_hat = confidence[i].argmax()\n",
    "        preds[i,y_hat] = 1\n",
    "        if y_hat != y_test[i]:\n",
    "            mistakes += 1\n",
    "            \n",
    "    return mistakes, preds, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Basic Results of Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_results(data,d_arr, kernel_choice, runs):\n",
    "    \"\"\"\n",
    "    For every value in d_arr, and using the kernel specified in kernel_choice,\n",
    "    it performs \"runs\" iterations where it trains a perceptron based on randomly selected\n",
    "    80% of the data and tests on the rest 20%.\n",
    "    :param d_arr: an array of d values\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param runs: the number of runs to perform\n",
    "    :return: two arrays: one containing the errors recorded in the training set in every run and one for the test set.\n",
    "    \"\"\"\n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "    training_set_errors = np.zeros((len(d_arr),runs))\n",
    "    test_set_errors = np.zeros((len(d_arr),runs))\n",
    "    \n",
    "    for d in d_arr:\n",
    "        for i in range(runs):\n",
    "            print(\"Now doing run \", i+1, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "            alphas,_ = perceptron_train(X_train, y_train, d, kernel_choice=kernel_choice)\n",
    "            # get training error and test error\n",
    "            train_errors,_,_ = perceptron_test(X_train, X_train, y_train, alphas, d, kernel_choice=kernel_choice)\n",
    "            test_errors,_,_ = perceptron_test(X_test, X_train, y_test, alphas, d, kernel_choice=kernel_choice)\n",
    "\n",
    "            training_set_errors[d-1, i] = train_errors / y_train.shape[0]\n",
    "            test_set_errors[d-1, i] = test_errors / y_test.shape[0]\n",
    "    return training_set_errors, test_set_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 20  for d= 7 .........\n",
      "Time taken:  0:14:07.533529\n"
     ]
    }
   ],
   "source": [
    "d_arr = np.arange(1,8)\n",
    "runs = 20\n",
    "startTime = datetime.now()\n",
    "training_set_errors, test_set_errors = basic_results(data,d_arr, 'Polynomial', runs)\n",
    "Part1_Q1 = datetime.now() - startTime\n",
    "print(\"\\nTime taken: \", Part1_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean_std(%)</th>\n",
       "      <th>test_mean_std(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.5867 +- 1.5759</td>\n",
       "      <td>9.5403 +- 1.5621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7065 +- 0.3968</td>\n",
       "      <td>3.6909 +- 0.5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1828 +- 0.0894</td>\n",
       "      <td>3.2070 +- 0.3963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1102 +- 0.0892</td>\n",
       "      <td>2.9543 +- 0.2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1418 +- 0.3603</td>\n",
       "      <td>2.9758 +- 0.5591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0437 +- 0.0272</td>\n",
       "      <td>2.8548 +- 0.3562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0383 +- 0.0177</td>\n",
       "      <td>2.9624 +- 0.3309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_mean_std(%)  test_mean_std(%)\n",
       "1  7.5867 +- 1.5759  9.5403 +- 1.5621\n",
       "2  0.7065 +- 0.3968  3.6909 +- 0.5596\n",
       "3  0.1828 +- 0.0894  3.2070 +- 0.3963\n",
       "4  0.1102 +- 0.0892  2.9543 +- 0.2832\n",
       "5  0.1418 +- 0.3603  2.9758 +- 0.5591\n",
       "6  0.0437 +- 0.0272  2.8548 +- 0.3562\n",
       "7  0.0383 +- 0.0177  2.9624 +- 0.3309"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_table(training_set_errors,test_set_errors):\n",
    "    train_mean=np.mean(training_set_errors,axis=1)\n",
    "    train_std=np.std(training_set_errors,axis=1)\n",
    "    test_mean=np.mean(test_set_errors,axis=1)\n",
    "    test_std=np.std(test_set_errors,axis=1)\n",
    "\n",
    "    mean_std = []\n",
    "    for i in range(len(train_mean)):\n",
    "        data_t = []\n",
    "        colomn_1 = \"{0:.4f} +- {1:.4f}\".format(train_mean[i]*100,train_std[i]*100)\n",
    "        \n",
    "        data_t.append(colomn_1)\n",
    "        colomn_2 = \"{0:.4f} +- {1:.4f}\".format(test_mean[i]*100,test_std[i]*100) \n",
    "        \n",
    "        data_t.append(colomn_2)\n",
    "        mean_std.append(data_t)\n",
    "    return mean_std\n",
    "\n",
    "# to construct table\n",
    "d_arr = np.arange(1,8)\n",
    "mean_std=construct_table(training_set_errors,test_set_errors)\n",
    "pd.DataFrame(data=mean_std,index=d_arr,columns=['train_mean_std(%)','test_mean_std(%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Add Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 runs , 1 d, train one cv.\n",
    "def cross_validation(x, y,d,kernel_choice,k):\n",
    "    \"\"\"\n",
    "    This function performs a k-fold cross validation on X, using a kernel of \"kernel_choice\" with parameter d.\n",
    "    :param X: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param d: the parameter of the kernel\n",
    "    :param k: the number of splits, i.e. the k parameter in k-fold Cross Validation\n",
    "    :return: the mean of test error across the k runs of the CV process and its standard deviation\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    mistake_arr = np.zeros(k)\n",
    "    i = 0\n",
    "    \n",
    "    for train_index, cv_index in kf.split(x):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        X_train = x[train_index]\n",
    "        X_cv = x[cv_index]\n",
    "        y_train = y[train_index]\n",
    "        y_cv = y[cv_index]\n",
    "    \n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d, kernel_choice = kernel_choice)\n",
    "        mistakes,_,_ = perceptron_test(X_cv, X_train, y_cv, alphas, d, kernel_choice = kernel_choice)\n",
    "        mistake_arr[i] = mistakes / len(y_cv)\n",
    "        i += 1\n",
    "        \n",
    "    return mistake_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_process(d_arr, runs, kernel_choice,x,y):\n",
    "    \"\"\"\n",
    "    This function performs 5-fold cross validation, multiple times (specified by runs argument) across the different\n",
    "    values of d specified in d_arr using the kernel specified in kernel_choice\n",
    "    :param d_arr: an array of d values\n",
    "    :param runs: The number of runs to repeat the CV process\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param calculate_confusions: Whether or not to also calculate confusions on the test set\n",
    "    :return: the array of d_stars, the test_errors and the confusions found\n",
    "    \"\"\"\n",
    "    d_stars = np.zeros(runs)\n",
    "    test_errors = np.zeros(runs)\n",
    "#     confusion_mtx_list = []\n",
    "    for run in range(runs):\n",
    "        single_confusion_mtx = np.zeros(shape = (10,10))\n",
    "        # In each run we will iterate through the d array and use all possible values of d\n",
    "        # Allocate 80/20 percent for training and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "        CV_means = np.zeros(len(d_arr))\n",
    "        for i in range(len(d_arr)):\n",
    "            print(\"Now doing run \", run+1, \"/\", runs, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "            mistake = cross_validation(X_train, y_train,d_arr[i],kernel_choice, k=5)\n",
    "            CV_means[i] = mistake\n",
    "            \n",
    "        # Train in whole 80% now with d_star\n",
    "        d_stars[run] = d_arr[CV_means.argmin()]\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d_stars[run], kernel_choice = kernel_choice)\n",
    "\n",
    "        mistakes,preds_test,_ = perceptron_test(X_test, X_train, y_test, alphas, d_stars[run], kernel_choice = kernel_choice)\n",
    "        test_errors[run] = mistakes / len(y_test)\n",
    "        \n",
    "    return d_stars,test_errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0:34:02.583907 d= 7 .........\n",
      "Mean d*:  5.4  with std:  0.8602325267042626\n",
      "Mean test error(%):  2.9892473118279574  with std(%):  0.4190100595354562\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "startTime = datetime.now()\n",
    "P_d_stars_array, P_test_errors_array = cv_process(d_arr, runs, 'Polynomial',x,y)\n",
    "time_OVA_cv = datetime.now() - startTime\n",
    "print(\"Time taken: \", time_OVA_cv)\n",
    "print(\"Mean d*: \", P_d_stars_array.mean(), \" with std: \", np.std(P_d_stars_array))\n",
    "print(\"Mean test error(%): \", P_test_errors_array.mean()*100, \" with std(%): \", np.std(P_test_errors_array)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 19  for d= 7 .........\r"
     ]
    }
   ],
   "source": [
    "single_confusion_mtx_list = []\n",
    "d_arr = np.arange(1,8)\n",
    "d_stars = np.zeros(20)\n",
    "\n",
    "for run in range(20):\n",
    "    single_confusion_mtx = np.zeros(shape = (10,10))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    CV_means = np.zeros(len(d_arr))\n",
    "    for i in range(len(d_arr)):\n",
    "        print(\"Now doing run \", run, \"/\", run, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "        MSE_CV_mean = cross_validation(X_train, y_train, d_arr[i],kernel_choice='Polynomial',k=5)\n",
    "        CV_means[i] = MSE_CV_mean\n",
    "\n",
    "    # Train in whole 80% now with d_star\n",
    "    d_stars[run] = d_arr[CV_means.argmin()]\n",
    "    alphas, errors = perceptron_train(X_train, y_train, d_stars[run], kernel_choice = 'Polynomial')\n",
    "    mistakes,preds_test,_ = perceptron_test(X_test, X_train, y_test, alphas, d_stars[run], kernel_choice = 'Polynomial')\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        # 每一行中最大的数的index，要和true class of y 进行比较\n",
    "        pred_label = preds_test[i].argmax()\n",
    "        if preds_test[i].argmax() != y_test[i]:\n",
    "            single_confusion_mtx[int(y_test[i]),int(pred_label)]+=1\n",
    "    single_confusion_mtx_list.append(single_confusion_mtx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col9 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col0 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col1 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col2 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col3 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col4 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col5 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col6 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col7 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col8 {\n",
       "            font-size:  8pt;\n",
       "        }    #T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col9 {\n",
       "            font-size:  8pt;\n",
       "        }</style><table id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>        <th class=\"col_heading level0 col9\" >9</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col0\" class=\"data row0 col0\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col1\" class=\"data row0 col1\" >30.00 +- 45.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col2\" class=\"data row0 col2\" >60.00 +- 91.65</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col3\" class=\"data row0 col3\" >50.00 +- 92.20</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col4\" class=\"data row0 col4\" >45.00 +- 58.95</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col5\" class=\"data row0 col5\" >40.00 +- 58.31</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col6\" class=\"data row0 col6\" >75.00 +- 94.21</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col7\" class=\"data row0 col7\" >15.00 +- 35.71</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col8\" class=\"data row0 col8\" >30.00 +- 45.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow0_col9\" class=\"data row0 col9\" >40.00 +- 58.31</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col0\" class=\"data row1 col0\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col1\" class=\"data row1 col1\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col2\" class=\"data row1 col2\" >20.00 +- 40.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col3\" class=\"data row1 col3\" >5.00 +- 21.79</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col4\" class=\"data row1 col4\" >70.00 +- 78.10</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col5\" class=\"data row1 col5\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col6\" class=\"data row1 col6\" >45.00 +- 66.90</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col7\" class=\"data row1 col7\" >10.00 +- 30.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col8\" class=\"data row1 col8\" >25.00 +- 43.30</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow1_col9\" class=\"data row1 col9\" >10.00 +- 43.59</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col0\" class=\"data row2 col0\" >50.00 +- 80.62</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col1\" class=\"data row2 col1\" >30.00 +- 45.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col2\" class=\"data row2 col2\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col3\" class=\"data row2 col3\" >80.00 +- 67.82</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col4\" class=\"data row2 col4\" >135.00 +- 101.37</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col5\" class=\"data row2 col5\" >20.00 +- 50.99</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col6\" class=\"data row2 col6\" >30.00 +- 55.68</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col7\" class=\"data row2 col7\" >70.00 +- 64.03</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col8\" class=\"data row2 col8\" >105.00 +- 92.06</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow2_col9\" class=\"data row2 col9\" >15.00 +- 35.71</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col0\" class=\"data row3 col0\" >30.00 +- 55.68</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col1\" class=\"data row3 col1\" >30.00 +- 55.68</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col2\" class=\"data row3 col2\" >120.00 +- 107.70</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col3\" class=\"data row3 col3\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col4\" class=\"data row3 col4\" >35.00 +- 57.23</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col5\" class=\"data row3 col5\" >335.00 +- 224.22</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col6\" class=\"data row3 col6\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col7\" class=\"data row3 col7\" >85.00 +- 101.37</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col8\" class=\"data row3 col8\" >180.00 +- 132.66</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow3_col9\" class=\"data row3 col9\" >30.00 +- 45.83</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col0\" class=\"data row4 col0\" >15.00 +- 35.71</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col1\" class=\"data row4 col1\" >110.00 +- 83.07</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col2\" class=\"data row4 col2\" >100.00 +- 77.46</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col3\" class=\"data row4 col3\" >15.00 +- 35.71</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col4\" class=\"data row4 col4\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col5\" class=\"data row4 col5\" >50.00 +- 86.60</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col6\" class=\"data row4 col6\" >65.00 +- 85.29</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col7\" class=\"data row4 col7\" >45.00 +- 58.95</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col8\" class=\"data row4 col8\" >10.00 +- 30.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow4_col9\" class=\"data row4 col9\" >180.00 +- 124.90</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col0\" class=\"data row5 col0\" >100.00 +- 94.87</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col1\" class=\"data row5 col1\" >15.00 +- 35.71</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col2\" class=\"data row5 col2\" >55.00 +- 58.95</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col3\" class=\"data row5 col3\" >135.00 +- 106.18</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col4\" class=\"data row5 col4\" >85.00 +- 96.31</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col5\" class=\"data row5 col5\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col6\" class=\"data row5 col6\" >135.00 +- 135.19</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col7\" class=\"data row5 col7\" >10.00 +- 30.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col8\" class=\"data row5 col8\" >80.00 +- 97.98</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow5_col9\" class=\"data row5 col9\" >50.00 +- 67.08</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col0\" class=\"data row6 col0\" >125.00 +- 94.21</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col1\" class=\"data row6 col1\" >50.00 +- 92.20</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col2\" class=\"data row6 col2\" >45.00 +- 66.90</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col3\" class=\"data row6 col3\" >5.00 +- 21.79</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col4\" class=\"data row6 col4\" >60.00 +- 86.02</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col5\" class=\"data row6 col5\" >55.00 +- 58.95</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col6\" class=\"data row6 col6\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col7\" class=\"data row6 col7\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col8\" class=\"data row6 col8\" >25.00 +- 53.62</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow6_col9\" class=\"data row6 col9\" >5.00 +- 21.79</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col0\" class=\"data row7 col0\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col1\" class=\"data row7 col1\" >45.00 +- 92.06</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col2\" class=\"data row7 col2\" >30.00 +- 45.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col3\" class=\"data row7 col3\" >5.00 +- 21.79</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col4\" class=\"data row7 col4\" >150.00 +- 156.52</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col5\" class=\"data row7 col5\" >15.00 +- 35.71</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col6\" class=\"data row7 col6\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col7\" class=\"data row7 col7\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col8\" class=\"data row7 col8\" >65.00 +- 72.63</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow7_col9\" class=\"data row7 col9\" >140.00 +- 115.76</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col0\" class=\"data row8 col0\" >105.00 +- 107.12</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col1\" class=\"data row8 col1\" >80.00 +- 74.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col2\" class=\"data row8 col2\" >115.00 +- 90.97</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col3\" class=\"data row8 col3\" >195.00 +- 146.54</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col4\" class=\"data row8 col4\" >95.00 +- 80.47</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col5\" class=\"data row8 col5\" >170.00 +- 130.77</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col6\" class=\"data row8 col6\" >50.00 +- 92.20</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col7\" class=\"data row8 col7\" >45.00 +- 58.95</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col8\" class=\"data row8 col8\" >0.00 +- 0.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow8_col9\" class=\"data row8 col9\" >25.00 +- 43.30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36clevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col0\" class=\"data row9 col0\" >30.00 +- 45.83</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col1\" class=\"data row9 col1\" >10.00 +- 30.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col2\" class=\"data row9 col2\" >35.00 +- 65.38</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col3\" class=\"data row9 col3\" >50.00 +- 74.16</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col4\" class=\"data row9 col4\" >175.00 +- 189.41</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col5\" class=\"data row9 col5\" >30.00 +- 55.68</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col6\" class=\"data row9 col6\" >5.00 +- 21.79</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col7\" class=\"data row9 col7\" >145.00 +- 128.35</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col8\" class=\"data row9 col8\" >10.00 +- 30.00</td>\n",
       "                        <td id=\"T_137d5828_52aa_11eb_aed6_8c8590d0c36crow9_col9\" class=\"data row9 col9\" >0.00 +- 0.00</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a22cfcdd0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusions_matrix = []\n",
    "for i in range(10):\n",
    "    confusions_i = []\n",
    "    for j in range(10):\n",
    "        confusions_ij = np.asarray([single_confusion_mtx_list[r][i,j] for r in range(20)])\n",
    "        confusions_i.append(\"{0:.2f} +- {1:.2f}\".format(confusions_ij.mean()*100, np.std(confusions_ij)*100))\n",
    "    confusions_matrix.append(confusions_i)\n",
    "    \n",
    "df = pd.DataFrame(data=confusions_matrix)\n",
    "df = df.style.set_properties(**{'font-size':'8pt'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_results(data,d_arr, kernel_choice, runs):\n",
    "    \"\"\"\n",
    "    For every value in d_arr, and using the kernel specified in kernel_choice,\n",
    "    it performs \"runs\" iterations where it trains a perceptron based on randomly selected\n",
    "    80% of the data and tests on the rest 20%.\n",
    "    :param d_arr: an array of d values\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param runs: the number of runs to perform\n",
    "    :return: two arrays: one containing the errors recorded in the training set in every run and one for the test set.\n",
    "    \"\"\"\n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "    training_set_errors = np.zeros((len(d_arr),runs))\n",
    "    test_set_errors = np.zeros((len(d_arr),runs))\n",
    "    \n",
    "    for d in d_arr:\n",
    "        for i in range(runs):\n",
    "            print(\"Now doing run \", i+1, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "            alphas,_ = perceptron_train(X_train, y_train, d, kernel_choice=kernel_choice)\n",
    "            # get training error and test error\n",
    "            train_errors,_,_ = perceptron_test(X_train, X_train, y_train, alphas, d, kernel_choice=kernel_choice)\n",
    "            test_errors,_,_ = perceptron_test(X_test, X_train, y_test, alphas, d, kernel_choice=kernel_choice)\n",
    "\n",
    "            training_set_errors[d-1, i] = train_errors / y_train.shape[0]\n",
    "            test_set_errors[d-1, i] = test_errors / y_test.shape[0]\n",
    "    return training_set_errors, test_set_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 20  for d= 7 .........\n",
      "Time taken:  0:16:06.326975\n"
     ]
    }
   ],
   "source": [
    "d_arr = np.arange(1,8)\n",
    "runs = 20\n",
    "\n",
    "startTime = datetime.now()\n",
    "g_training_set_errors, G_test_set_errors = basic_results(data,d_arr, 'Gaussian', runs)\n",
    "Part1_Q5 = datetime.now() - startTime\n",
    "print(\"\\nTime taken: \", Part1_Q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean_std(%)</th>\n",
       "      <th>test_mean_std(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0013 +- 0.0040</td>\n",
       "      <td>6.7554 +- 0.5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>6.9677 +- 0.4629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0013 +- 0.0040</td>\n",
       "      <td>7.0027 +- 0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0034 +- 0.0058</td>\n",
       "      <td>6.8333 +- 0.6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0034 +- 0.0072</td>\n",
       "      <td>7.1720 +- 0.6043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0013 +- 0.0040</td>\n",
       "      <td>8.4032 +- 0.4818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0027 +- 0.0069</td>\n",
       "      <td>10.3629 +- 0.6160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_mean_std(%)   test_mean_std(%)\n",
       "1  0.0013 +- 0.0040   6.7554 +- 0.5632\n",
       "2  0.0000 +- 0.0000   6.9677 +- 0.4629\n",
       "3  0.0013 +- 0.0040   7.0027 +- 0.5443\n",
       "4  0.0034 +- 0.0058   6.8333 +- 0.6265\n",
       "5  0.0034 +- 0.0072   7.1720 +- 0.6043\n",
       "6  0.0013 +- 0.0040   8.4032 +- 0.4818\n",
       "7  0.0027 +- 0.0069  10.3629 +- 0.6160"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to construct table\n",
    "d_arr = np.arange(1,8)\n",
    "mean_std=construct_table(training_set_errors,test_set_errors)\n",
    "pd.DataFrame(data=mean_std,index=d_arr,columns=['train_mean_std(%)','test_mean_std(%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0:37:39.421615 d= 7 .........\n",
      "Mean d*:  2.45  with std:  1.3219304066402287\n",
      "Mean test error(%):  6.946236559139783  with std(%):  0.4801529798229272\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "startTime = datetime.now()\n",
    "d_stars_array, gk_test_errors_array= cv_process(d_arr, runs, 'Gaussian',x,y)\n",
    "time_gk_cv = datetime.now() - startTime\n",
    "print(\"Time taken: \", time_gk_cv)\n",
    "print(\"Mean d*: \", d_stars_array.mean(), \" with std: \", np.std(d_stars_array))\n",
    "print(\"Mean test error(%): \", gk_test_errors_array.mean()*100, \" with std(%): \", np.std(gk_test_errors_array)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Five Hardest Digit to Find "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hardest_images(indices):\n",
    "    \"\"\"\n",
    "    This helper function plots images in an 1x(len(indices)) grid of plots.\n",
    "    :param indices: The indices of examples to plot (from array 'x')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(30,30))\n",
    "    k = 1\n",
    "    for i in indices:\n",
    "        a1 = plt.subplot(1, len(indices), k)\n",
    "        pixels = np.array(x[i], dtype='uint8')\n",
    "        pixels = pixels.reshape((16, 16))\n",
    "        plt.title(\"Real: {0}\".format(y[i]))\n",
    "        a1.imshow(pixels, cmap='gray')\n",
    "        k+=1\n",
    "        \n",
    "def find_hardest_elements(x, y, d_star, runs, k_splits=5):\n",
    "    \"\"\"\n",
    "    This function performs a number of runs over the data set in order to find the 5 images which are the most\n",
    "    difficult to predict. The way this process is done is the following:\n",
    "        - We perform a 5-fold split over the data set, dividing into 80% for training and 20% for testing\n",
    "        - We use the mean d_star as calculated over 20 runs of CV in the data set, to train a perceptron on the 80%\n",
    "          of the data set.\n",
    "        - We predict the remaining 20% and we store the confidences we obtain in each split and run\n",
    "    At the end of the process, we sort the confidences in ascending order and return the 5 first indices\n",
    "    (i.e. the observations which were harder to predict)\n",
    "    :param x: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param d_star: the value of d to use while training the perceptron\n",
    "    :param runs: the number of runs to perform\n",
    "    :param k_splits: the number of splits to perform while generating the training/test sets.\n",
    "    :return: the indices of the elements of x, that we predict the least confidence with\n",
    "    \"\"\"\n",
    "    least_confidences = np.zeros(data.shape[0])\n",
    "    \n",
    "    for run in range(runs):\n",
    "        print(\"Finding hardest elements, run \", run+1, \"/\", runs,\".....\", end='\\r')\n",
    "        \n",
    "        # Split into 80%/20% for training and test set\n",
    "        kf = KFold(n_splits=k_splits, shuffle=True)\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            X_train = x[train_index]\n",
    "            X_test = x[test_index]\n",
    "            y_train = y[train_index]\n",
    "            y_test = y[test_index]\n",
    "\n",
    "            alphas,_ = perceptron_train(X_train, y_train, d_star)\n",
    "            _, preds_test, confidences = perceptron_test(X_test, X_train, y_test, alphas, d_star)\n",
    "            \n",
    "            for i in range(X_test.shape[0]):\n",
    "                pred_label = preds_test[i].argmax()\n",
    "                least_confidences[test_index[i]] += confidences[i][int(y_test[i])] / 5\n",
    "    \n",
    "    least_confidences /= runs\n",
    "\n",
    "    conf_indices = np.argsort(least_confidences)[:5]\n",
    "    return conf_indices, np.sort(least_confidences)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding hardest elements, run  20 / 20 .....\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_indices, least_confidences = find_hardest_elements(x, y, int(d_stars_array.mean()), runs=20)\n",
    "plot_hardest_images(conf_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-One Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train_ovo(x,y,d=2,kernel_choice='Polynomial', tol=0.01):\n",
    "    \"\"\"\n",
    "    This function trains the classifiers needed for the one-versus-one approach of perceptron\n",
    "    :param x: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param d: the value of d used in the calculation of the kernel matrix\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param tol: a threshold value which denotes the minimum change in error rate that we should have\n",
    "    in order to continue training\n",
    "    :return: a set of weights alpha (matrix of (m X n X n), where m is the number of examples,\n",
    "    n is the number of classes) and the number of errors in the last epoch\n",
    "    \"\"\"\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    classes_num = 10 #number of classes \n",
    "    max_epoch = 10 #the maximum number of epochs to perform while training the perceptrons\n",
    "    error_per_epoch = np.zeros(max_epoch)\n",
    "    errors = np.zeros(m)\n",
    "    K_train = train_kernel(x, d, kernel_choice)\n",
    "    alpha_mtx = np.zeros((m,classes_num,classes_num)) \n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        errors = np.zeros(m)\n",
    "        num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "    \n",
    "        #iterate through training set\n",
    "        for t in range(m):\n",
    "            if t==0:\n",
    "                alpha_mtx_prev = alpha_mtx[0,:,:] #when t=0, the previous alpha is set to be 0\n",
    "            else:\n",
    "                alpha_mtx_prev = alpha_mtx[t-1,:,:] #\n",
    "\n",
    "            x_t = x[t,:]\n",
    "            y_t = y[t]\n",
    "\n",
    "            votes_mtx = np.zeros((classes_num, classes_num)) #zero on the horizontal. \n",
    "            classes_list = np.array(range(classes_num))\n",
    "\n",
    "            for i in range(classes_num):\n",
    "                c1 = classes_list[i]\n",
    "                classes_rest = classes_list[classes_list>c1]\n",
    "                for j in range(len(classes_rest)):\n",
    "                    c2 = classes_rest[j]\n",
    "                    alpha_ovo = alpha_mtx[:,c1,c2]\n",
    "#                   returns the signs denoting the votes of the one-versus-one classifier,(1,-1)\n",
    "                    vote = np.sign(((alpha_ovo[:].T @K_train[t,:]).T))\n",
    "                    #vote = classifier_ovo(c1,c2,K_train,alpha_ovo,iter_num=t)\n",
    "                    votes_mtx[c1,c2] = vote\n",
    "\n",
    "            #Count the votes in the matrix\n",
    "            votes_count = votes_mtx.sum(axis=0) # sum every row\n",
    "            pred_t = votes_count.argmax()\n",
    "\n",
    "            if pred_t!=y_t:\n",
    "                num_errors +=1\n",
    "                alpha_t = alpha_mtx_prev #initialize it to its previous form\n",
    "                alpha_t[:,int(y_t)] =+1 # column belonging to correct label class +=1\n",
    "                alpha_t[:,int(pred_t)] =-1 # column belonging to false predicted class -=1\n",
    "\n",
    "                #store alpha_t into the matrix for future reference\n",
    "                alpha_mtx[t,:,:] = alpha_t\n",
    "            \n",
    "            errors[t] = num_errors \n",
    "\n",
    "        error_per_epoch[epoch] = errors[-1]\n",
    "        \n",
    "        if epoch>1:\n",
    "            diff_rates = (error_per_epoch[epoch-1] - error_per_epoch[epoch])/m\n",
    "            \n",
    "            #Stop if the error rate has increased, \n",
    "            #or the difference in error rate between the previous one and the current one < tolerance. \n",
    "            if diff_rates<tol or diff_rates<0:\n",
    "#                 print('difference in error rate', diff_rates)\n",
    "#                 print('break point at epoch=', epoch )\n",
    "                break\n",
    "        \n",
    "    return alpha_mtx, error_per_epoch[:epoch+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test_ovo(x_test,x_train,y_test,alpha_mtx, d,kernel_choice='Polynomial'):\n",
    "    \"\"\"\n",
    "    This function predicts the label values of the examples found in x_test array using the one-versus-one perceptrons\n",
    "    approach.\n",
    "    :param x_test: a set of unseen examples that we wish to get predictions on\n",
    "    :param x_train: the set of observations that the perceptrons have been trained on\n",
    "    :param y_test: the true labels of x_test, used for calculating error rates\n",
    "    :param alphas: the set of weights used for the perceptrons\n",
    "    :param d: the value of d used in the calculation of the kernel matrix\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :return: the number of mistakes done on the test set as well as the actual predictions\n",
    "    \"\"\"\n",
    "    m_test = x_test.shape[0]\n",
    "    m_train = x_train.shape[0]\n",
    "    \n",
    "    K_test = test_kernel(x_train, x_test, d, kernel_choice)\n",
    "    \n",
    "    classes_num = 10\n",
    "    classes_list = np.array(range(classes_num))\n",
    "    votes_mtx =np.zeros((m_test,10,10))\n",
    "    \n",
    "    for i in range(classes_num):\n",
    "        c1 = classes_list[i]\n",
    "        classes_rest = classes_list[classes_list>c1]\n",
    "        for j in range(len(classes_rest)):\n",
    "            c2 = classes_rest[j]\n",
    "            alphas_c1c2 = alpha_mtx[:,int(c1),int(c2)]\n",
    "            vote = np.sign(alphas_c1c2.T@K_test) \n",
    "            votes_mtx[:,c1,c2] = vote\n",
    "                \n",
    "    sum_votes = np.sum(votes_mtx,axis=1)\n",
    "    pred = sum_votes.argmax(axis=1)\n",
    "    diff = pred - y_test\n",
    "    mistakes = len(np.flatnonzero(diff))\n",
    "    \n",
    "    return mistakes,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_results_ovo(x,y,d_arr, kernel_choice, runs):\n",
    "    \"\"\"\n",
    "    Produces the basic results for the one versus one perceptron approach\n",
    "    :param d_arr: an array of d values\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param runs: the number of runs to perform to calculate the error rates\n",
    "    :return: the training and test error rates in each run\n",
    "    \"\"\"\n",
    "    training_set_errors = np.zeros((len(d_arr),runs))\n",
    "    test_set_errors = np.zeros((len(d_arr),runs))\n",
    "\n",
    "    for d in d_arr:\n",
    "        for i in range(runs):\n",
    "            print(\"Now doing run \", i+1, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "            startTime = datetime.now()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "            alphas,train_errors = perceptron_train_ovo(X_train,y_train, d)\n",
    "            test_error ,predictions,= perceptron_test_ovo(X_test,X_train, y_test, alphas,d)\n",
    "\n",
    "            a = X_train.shape[0]\n",
    "            b = X_test.shape[0]\n",
    "            training_set_errors[d-1, i] = train_errors[-1] / a\n",
    "            test_set_errors[d-1, i] = test_error / b\n",
    "\n",
    "#             print(\"Now doing run \", i, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "#             print(\"Time taken: \", datetime.now() - startTime)\n",
    "    return training_set_errors, test_set_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 20  for d= 7 .........\n",
      "Time taken:  1:11:39.246889\n"
     ]
    }
   ],
   "source": [
    "d_arr = np.arange(1,8)\n",
    "runs = 20\n",
    "startTime = datetime.now()\n",
    "training_set_errors, test_set_errors = basic_results_ovo(x,y,d_arr, 'Polynomial', runs)\n",
    "Part1_Q6 = datetime.now() - startTime\n",
    "print(\"\\nTime taken: \", Part1_Q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean_std</th>\n",
       "      <th>test_mean_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3211 +- 0.5788</td>\n",
       "      <td>13.8172 +- 1.0472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9797 +- 0.4245</td>\n",
       "      <td>8.0484 +- 0.7157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4165 +- 0.5087</td>\n",
       "      <td>6.7473 +- 0.6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0869 +- 0.2195</td>\n",
       "      <td>5.5887 +- 0.5264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.3407 +- 0.3937</td>\n",
       "      <td>5.6210 +- 0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0933 +- 0.3671</td>\n",
       "      <td>5.1022 +- 0.5467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.8412 +- 0.2261</td>\n",
       "      <td>5.1989 +- 0.5956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_mean_std      test_mean_std\n",
       "1  14.3211 +- 0.5788  13.8172 +- 1.0472\n",
       "2   6.9797 +- 0.4245   8.0484 +- 0.7157\n",
       "3   4.4165 +- 0.5087   6.7473 +- 0.6515\n",
       "4   3.0869 +- 0.2195   5.5887 +- 0.5264\n",
       "5   2.3407 +- 0.3937   5.6210 +- 0.6192\n",
       "6   2.0933 +- 0.3671   5.1022 +- 0.5467\n",
       "7   1.8412 +- 0.2261   5.1989 +- 0.5956"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_arr = np.arange(1,8)\n",
    "ovo_mean_std=construct_table(training_set_errors,test_set_errors)\n",
    "pd.DataFrame(data=ovo_mean_std,index=d_arr,columns=['train_mean_std','test_mean_std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add CV to OvO with poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_ovo(x, y,d,kernel_choice,k):\n",
    "    \"\"\"\n",
    "    This function performs a k-fold cross validation on X, using a kernel of \"kernel_choice\" with parameter d.\n",
    "    :param X: the observations array\n",
    "    :param y: the labels vector\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param d: the parameter of the kernel\n",
    "    :param k: the number of splits, i.e. the k parameter in k-fold Cross Validation\n",
    "    :return: the mean of test error across the k runs of the CV process and its standard deviation\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    mistake_arr = np.zeros(k)\n",
    "    i = 0\n",
    "    \n",
    "    for train_index, cv_index in kf.split(x):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        X_train = x[train_index]\n",
    "        X_cv = x[cv_index]\n",
    "        y_train = y[train_index]\n",
    "        y_cv = y[cv_index]\n",
    "    \n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        alphas, errors = perceptron_train_ovo(X_train, y_train, d, kernel_choice = kernel_choice)\n",
    "        mistakes,_ = perceptron_test_ovo(X_cv, X_train, y_cv, alphas, d, kernel_choice = kernel_choice)\n",
    "        mistake_arr[i] = mistakes / len(y_cv)\n",
    "        i += 1\n",
    "        \n",
    "    return mistake_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_process(d_arr, runs, kernel_choice,x,y):\n",
    "    \"\"\"\n",
    "    This function performs 5-fold cross validation, multiple times (specified by runs argument) across the different\n",
    "    values of d specified in d_arr using the kernel specified in kernel_choice\n",
    "    :param d_arr: an array of d values\n",
    "    :param runs: The number of runs to repeat the CV process\n",
    "    :param kernel_choice: Depending on the kernel choice, can be {'Polynomial', 'Gaussian'}\n",
    "    :param calculate_confusions: Whether or not to also calculate confusions on the test set\n",
    "    :return: the array of d_stars, the test_errors and the confusions found\n",
    "    \"\"\"\n",
    "    d_stars = np.zeros(runs)\n",
    "    test_errors = np.zeros(runs)\n",
    "    for run in range(runs):\n",
    "        single_confusion_mtx = np.zeros(shape = (10,10))\n",
    "        # In each run we will iterate through the d array and use all possible values of d\n",
    "        # Allocate 80/20 percent for training and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "        CV_means = np.zeros(len(d_arr))\n",
    "        for i in range(len(d_arr)):\n",
    "            print(\"Now doing run \", run+1, \"/\", runs, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "            mistake = cross_validation_ovo(X_train, y_train,d_arr[i],kernel_choice, k=5)\n",
    "            CV_means[i] = mistake\n",
    "            \n",
    "        # Train in whole 80% now with d_star\n",
    "        d_stars[run] = d_arr[CV_means.argmin()]\n",
    "        alphas, errors = perceptron_train_ovo(X_train, y_train, d_stars[run], kernel_choice = kernel_choice)\n",
    "\n",
    "        mistakes,preds_test = perceptron_test_ovo(X_test, X_train, y_test, alphas, d_stars[run], kernel_choice = kernel_choice)\n",
    "        test_errors[run] = mistakes / len(y_test)\n",
    "                   \n",
    "    return d_stars,test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  5:04:58.301049 d= 7 .........\n",
      "Mean d*:  6.6  with std(%):  66.33249580710799\n",
      "Mean test error(%):  5.123655913978494  with std(%):  0.5344259100202382\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "startTime = datetime.now()\n",
    "\n",
    "d_stars_array, test_errors_array= cv_process(d_arr, runs, 'Polynomial',x,y)\n",
    "time_pp_cv = datetime.now() - startTime\n",
    "print(\"Time taken: \", time_pp_cv)\n",
    "print(\"Mean d*: \", d_stars_array.mean(), \" with std: \", np.std(d_stars_array))\n",
    "print(\"Mean test error(%): \", test_errors_array.mean()*100, \" with std(%): \", np.std(test_errors_array)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
